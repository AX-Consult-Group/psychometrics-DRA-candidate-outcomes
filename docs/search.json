[
  {
    "objectID": "psychometrics-candidate-outcomes.html",
    "href": "psychometrics-candidate-outcomes.html",
    "title": "psychometrics-candidate-outcomes",
    "section": "",
    "text": "This report presents an example analysis of how psychometric assessment scores relate to real-world employment and placement outcomes among candidates in a training and placement programme.\n\n\nCandidates were screened using the Dynamic Risk Assessment as part of the recruitment process.\nFollowing successful selection, a follow-up survey was administered to track key employment outcomes, including placement completion, specialised training uptake, absorption by host companies, further studies, and current employment status.\n\n\n\nThe primary goal of this analysis is to evaluate the predictive validity of the DRA ‚Äî that is, whether the risk scores can meaningfully distinguish between different outcome groups and help forecast long-term success.\n\n\n\n\nDescriptive statistics and visual comparisons of risk scores across outcome categories\nSMOTE oversampling to address class imbalance in predictive modelling\nROC curves for discrimination\nRandom forest modelling for classification and predictor importance\n\n\n\n\nAll data is simulated to match realistic distributions, correlations, and patterns from the original analysis. No real data is included.\nTo protect intellectual property, DRA dimension names have been generalised.\n\n\nShow code\nlibrary(pacman)\np_load(dplyr, readxl, writexl, haven, ggplot2, tidyr, lavaan, psych, broom, tidyverse, knitr, ggcorrplot, jtools, Hmisc, rempsyc, RColorBrewer, smotefamily, caret, pROC, themis, recipes, yardstick, randomForest, copula, reshape2, stringr) \n\nraw_data &lt;- readxl::read_excel(\"simulated_candidate_data.xlsx\")\ndim(raw_data)\n\n\n[1] 217  14\n\n\nThe sample consists of 217 employees.\n\n\nShow code\nraw_data &lt;- raw_data %&gt;% \n  dplyr::mutate(Work_Readiness_Completion = as.factor(Work_Readiness_Completion), \n                Placement_Contract_Completion = as.factor(Placement_Contract_Completion), \n                Specialised_Training_Completion = as.factor(Specialised_Training_Completion), \n                Current_Employment_Status = as.factor(Current_Employment_Status), \n                Absorbed_Host_Company = as.factor(Absorbed_Host_Company), \n                Further_Studies = as.factor(Further_Studies))\n\n\n\n\n\nThis section provides an overview of the simulated data, including correlations among DRA dimensions and risk scores, outlier detection, and group comparisons across key outcomes.\n\n\nThe Spearman correlations show strong interrelationships among the DRA dimensions and risk components:\n\nRisk Mitigators shows a strong, negative association with Risk Drivers (-0.77, p&lt;0.001), as expected in the assessment design.\nSimilarly, the Composite Risk Score shows a strong, positive correlation with Risk Drivers (0.92, p&lt;0.001) and a strong negative correlation with Risk Mitigators (-0.95, p&lt;0.001).\n\nWeak or non-significant correlations (e.g., Uncertainty with Principles, r=0.00) highlight independent aspects of the profile.\n\n\nShow code\ncorrelations &lt;- raw_data %&gt;% \n  dplyr::select(c(1:8))\n\nflattenCorrMatrix &lt;- function(cormat, pmat) {\n  ut &lt;- upper.tri(cormat)\n  data.frame(\n    row=rownames(cormat)[row(cormat)[ut]],\n    column=rownames(cormat)[col(cormat)[ut]],\n    cor=(cormat)[ut],\n    p=pmat[ut]\n  )\n}\n\ncor_sig &lt;- Hmisc::rcorr(as.matrix(correlations), type = \"spearman\") \n\ncorrelation_table &lt;- flattenCorrMatrix(cor_sig$r, cor_sig$P) %&gt;%\n  mutate(\n    cor = round(cor, 3),   \n    p   = round(p, 3)       \n  ) \n\ncorrelation_table %&gt;%\n  mutate(\n    cor = round(cor, 3),\n    p   = round(p, 3),\n    ` ` = case_when(p &lt; 0.001 ~ \"***\", p &lt; 0.01 ~ \"**\", p &lt; 0.05 ~ \"*\", TRUE ~ \"\")\n  ) %&gt;%\n  select(`Variable 1` = row, `Variable 2` = column, Correlation = cor, `p-value` = p, Significance = ` `) %&gt;%\n  kable(\n    caption = \"Spearman Correlations (significant p &lt; 0.05)\",\n    digits  = 3,\n    align   = c(\"l\", \"l\", \"r\", \"r\", \"c\")\n  )\n\n\n\nSpearman Correlations (significant p &lt; 0.05)\n\n\n\n\n\n\n\n\n\nVariable 1\nVariable 2\nCorrelation\np-value\nSignificance\n\n\n\n\nCore_Traits\nEmotional_Understanding\n-0.230\n0.001\n**\n\n\nCore_Traits\nJudgement\n0.262\n0.000\n***\n\n\nEmotional_Understanding\nJudgement\n-0.018\n0.792\n\n\n\nCore_Traits\nPrinciples\n0.171\n0.011\n*\n\n\nEmotional_Understanding\nPrinciples\n0.093\n0.172\n\n\n\nJudgement\nPrinciples\n0.152\n0.025\n*\n\n\nCore_Traits\nUncertainty\n0.044\n0.521\n\n\n\nEmotional_Understanding\nUncertainty\n-0.098\n0.149\n\n\n\nJudgement\nUncertainty\n0.443\n0.000\n***\n\n\nPrinciples\nUncertainty\n0.003\n0.960\n\n\n\nCore_Traits\nRisk_Mitigators\n-0.683\n0.000\n***\n\n\nEmotional_Understanding\nRisk_Mitigators\n-0.183\n0.007\n**\n\n\nJudgement\nRisk_Mitigators\n-0.380\n0.000\n***\n\n\nPrinciples\nRisk_Mitigators\n-0.502\n0.000\n***\n\n\nUncertainty\nRisk_Mitigators\n-0.085\n0.211\n\n\n\nCore_Traits\nRisk_Drivers\n0.593\n0.000\n***\n\n\nEmotional_Understanding\nRisk_Drivers\n0.329\n0.000\n***\n\n\nJudgement\nRisk_Drivers\n0.353\n0.000\n***\n\n\nPrinciples\nRisk_Drivers\n0.539\n0.000\n***\n\n\nUncertainty\nRisk_Drivers\n-0.025\n0.719\n\n\n\nRisk_Mitigators\nRisk_Drivers\n-0.766\n0.000\n***\n\n\nCore_Traits\nComposite_Risk_Score\n0.683\n0.000\n***\n\n\nEmotional_Understanding\nComposite_Risk_Score\n0.255\n0.000\n***\n\n\nJudgement\nComposite_Risk_Score\n0.396\n0.000\n***\n\n\nPrinciples\nComposite_Risk_Score\n0.544\n0.000\n***\n\n\nUncertainty\nComposite_Risk_Score\n0.029\n0.673\n\n\n\nRisk_Mitigators\nComposite_Risk_Score\n-0.952\n0.000\n***\n\n\nRisk_Drivers\nComposite_Risk_Score\n0.915\n0.000\n***\n\n\n\n\n\n\n\nShow code\nmodel.matrix(~0+., correlations) %&gt;% \n  cor(use='pairwise.complete.obs', method = \"spearman\") %&gt;% \n  ggcorrplot(sig.level=0.5, \n             hc.order = TRUE, \n             show.diag = FALSE, \n             type = \"lower\", \n             lab_size=0.5) +\n  xlab(\"Variable 1\") + \n  ylab(\"Variable 2\") +\n  theme_apa(legend.pos = \"right\", legend.use.title = FALSE,\n  legend.font.size = 12, x.font.size = 12, y.font.size = 12,\n  facet.title.size = 12, remove.y.gridlines = TRUE,\n  remove.x.gridlines = TRUE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\n‚Ñπ Please use tidy evaluation idioms with `aes()`.\n‚Ñπ See also `vignette(\"ggplot2-in-packages\")` for more information.\n‚Ñπ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n\n\nShow code\n# Detecting outliers using the IQR method \n\nQ1 &lt;- quantile(raw_data$Composite_Risk_Score, 0.25)\nQ3 &lt;- quantile(raw_data$Composite_Risk_Score, 0.75)\nIQR &lt;- Q3 - Q1\noutliers &lt;- which(raw_data$Composite_Risk_Score&lt; (Q1 - 1.5 * IQR) | raw_data$Composite_Risk_Score &gt; (Q3 + 1.5 * IQR))\n\nif (length(outliers) &gt; 0) {\n  # Extract the values of outliers\n  outlier_values &lt;- raw_data$Composite_Risk_Score[outliers]\n\n  # Print values\n  print(raw_data)\n} else {\n  print(\"No outliers were found using the IQR method.\")\n}\n\n\n[1] \"No outliers were found using the IQR method.\"\n\n\nNo outliers were detected in the Composite Risk Score using the IQR method, suggesting the data is free from extreme values that could skew results.\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Work_Readiness_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Work_Readiness_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Work Readiness Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nWork Readiness Completion\n\n\nWork_Readiness_Completion\nCount\nPercentage\n\n\n\n\nYes\n217\n100%\n\n\n\n\n\nSince all 217 candidates completed the work readiness assessment, this variable was excluded for predictive analysis.\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Placement_Contract_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Placement_Contract_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Placement Contract Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nPlacement Contract Completion\n\n\nPlacement_Contract_Completion\nCount\nPercentage\n\n\n\n\nIn progress\n51\n23.5%\n\n\nNo\n24\n11.1%\n\n\nYes\n142\n65.4%\n\n\n\n\n\nThe majority (65.7%) completed their placement contract, with 23.1% still in progress and 11.1% not completing.\n\n\nShow code\nPlacement_Contract_Completion_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Placement_Contract_Completion, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Placement_Contract_Completion_Means)\n\n\n\n\n\nPlacement_Contract_Completion\nMean_Composite_Risk\n\n\n\n\nIn progress\n31.49\n\n\nYes\n34.05\n\n\nNo\n36.06\n\n\n\n\n\nEmployees who are still completing their placement contract had the lowest average composite risk score (31.49) whereas employees who did not complete their placement contracts had the highest average composite risk score (36.06).\n\n\nShow code\nggplot(raw_data, \n       aes(x = Placement_Contract_Completion,\n           y = Composite_Risk_Score, \n           fill = Placement_Contract_Completion)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score by Placement Contract Completion\",\n       x = \"Placement Contract Completion\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"In progress\" = \"orange\", \"No\" = \"red\", \n                               \"Yes\" = \"lightgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Specialised_Training_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Specialised_Training_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Specialised Training Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nSpecialised Training Completion\n\n\nSpecialised_Training_Completion\nCount\nPercentage\n\n\n\n\nNo\n36\n16.6%\n\n\nYes\n181\n83.4%\n\n\n\n\n\nMost candidates (83.4%) completed specialised training.\n\n\nShow code\nSpecialised_Training_Completion_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Specialised_Training_Completion, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Specialised_Training_Completion_Means)\n\n\n\n\n\nSpecialised_Training_Completion\nMean_Composite_Risk\n\n\n\n\nYes\n32.45\n\n\nNo\n39.81\n\n\n\n\n\nEmployees who completed specialized training had a lower average composite risk score compared to those who did not.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Specialised_Training_Completion,\n           y = Composite_Risk_Score, \n           fill = Specialised_Training_Completion)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score by Specialised Training Completion\",\n       x = \"Specialised Training Completion\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"lightgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Current_Employment_Status) %&gt;%\n  na.omit() %&gt;%\n  group_by(Current_Employment_Status) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Current Employment Status\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nCurrent Employment Status\n\n\nCurrent_Employment_Status\nCount\nPercentage\n\n\n\n\nFull_time\n26\n12%\n\n\nPart_time\n16\n7.4%\n\n\nSelf_employed\n1\n0.5%\n\n\nTemporary_Contract\n118\n54.4%\n\n\nUnemployed\n56\n25.8%\n\n\n\n\n\nThe most common employment status is Temporary Contract (54.4%), followed by Unemployed (25.8%). Self employed was excluded due to rarity (n=1) resulting in a sample size of 216.\n\n\nShow code\nraw_data &lt;- raw_data %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  filter(Current_Employment_Status != \"Self_employed\") %&gt;% \n  ungroup()\n  \nCurrent_Employment_Status_Means &lt;- raw_data %&gt;%\n  ungroup() %&gt;% \n  dplyr::select(c(Current_Employment_Status, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  filter(Current_Employment_Status != \"Self_employed\") %&gt;% \n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Current_Employment_Status_Means)\n\n\n\n\n\nCurrent_Employment_Status\nMean_Composite_Risk\n\n\n\n\nUnemployed\n28.59\n\n\nTemporary_Contract\n34.59\n\n\nFull_time\n37.94\n\n\nPart_time\n38.52\n\n\n\n\n\nEmployees with part-time contracts have the highest average composite risk (38.52), while candidates who are currently unemployed have the lowest (28.59).\n\n\nShow code\nggplot(raw_data, \n       aes(x = Current_Employment_Status,\n           y = Composite_Risk_Score, \n           fill = Current_Employment_Status)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of Composite Risk Score by Current Employment Status\",\n       x = \"Current Employment Status\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Unemployed\" = \"red\", \n                               \"Full_time\" = \"darkgreen\", \n                               \"Part_time\" = \"gold\",\n                               \"Temporary_Contract\" = \"darkorange\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Absorbed_Host_Company) %&gt;%\n  na.omit() %&gt;%\n  group_by(Absorbed_Host_Company) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Absorbed by Host Company\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nAbsorbed by Host Company\n\n\nAbsorbed_Host_Company\nCount\nPercentage\n\n\n\n\nNo\n200\n92.6%\n\n\nYes\n16\n7.4%\n\n\n\n\n\nOnly 7.4% of employees were absorbed by their respective host company. However, this variable is likely skewed because the economy is saturated and businesses cannot accommodate more employees rendering this criterion relatively less useful for prediction.\n\n\nShow code\nAbsorbed_Host_Company_Means &lt;- raw_data %&gt;%\n  ungroup() %&gt;% \n  dplyr::select(c(Absorbed_Host_Company, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Absorbed_Host_Company) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Absorbed_Host_Company_Means)\n\n\n\n\n\nAbsorbed_Host_Company\nMean_Composite_Risk\n\n\n\n\nNo\n33.49\n\n\nYes\n36.68\n\n\n\n\n\nEmployees who were absorbed by their host company had a slightly higher average composite risk score.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Absorbed_Host_Company,\n           y = Composite_Risk_Score, \n           fill = Absorbed_Host_Company)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score\",\n       x = \"Absorbed by Host Company\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"darkgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Further_Studies) %&gt;%\n  na.omit() %&gt;%\n  group_by(Further_Studies) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Further Studies\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nFurther Studies\n\n\nFurther_Studies\nCount\nPercentage\n\n\n\n\nNo\n197\n91.2%\n\n\nYes\n19\n8.8%\n\n\n\n\n\nOnly 8.8% pursued further studies however this is likely influenced by various external factors such as age, current level of education, and affordability.\n\n\nShow code\nFurther_Studies_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Further_Studies, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Further_Studies) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Further_Studies_Means)\n\n\n\n\n\nFurther_Studies\nMean_Composite_Risk\n\n\n\n\nYes\n28.51\n\n\nNo\n34.23\n\n\n\n\n\nLower risk is linked to continued education, suggesting the DRA can identify motivated, resilient candidates likely to seek growth opportunities.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Further_Studies,\n           y = Composite_Risk_Score, \n           fill = Further_Studies)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score\",\n       x = \"Further Studies\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"darkgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nPC_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  PC_dimension_summary,\n  digits = 2,                  \n  caption = \"Placement Contract Completion: Mean DRA Dimension Scores\"\n)\n\n\n\nPlacement Contract Completion: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nPlacement_Contract_Completion\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nIn progress\n34.46\n50.40\n43.50\n39.73\n29.32\n\n\nNo\n46.46\n42.51\n42.85\n30.16\n26.23\n\n\nYes\n31.87\n56.87\n36.73\n39.30\n29.90\n\n\n\n\n\nShow code\nPC_dimension_summary_long &lt;- PC_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(PC_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Placement_Contract_Completion)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Placement Contract Completion\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\n  \"No\"       = \"#7F8C8D\",     \n  \"Yes\"      = \"#27AE60\",     \n  \"In progress\" = \"#16A085\"  \n))\n\n\n\n\n\n\n\nShow code\nSTC_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  STC_dimension_summary,\n  digits = 2,                  \n  caption = \"Specialised Training Completion: Mean DRA Dimension Scores\"\n)\n\n\n\nSpecialised Training Completion: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nSpecialised_Training_Completion\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n39.84\n50.83\n41.13\n39.63\n38.06\n\n\nYes\n32.94\n54.36\n38.55\n38.13\n27.62\n\n\n\n\n\nShow code\nSTC_dimension_summary_long &lt;- STC_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(STC_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Specialised_Training_Completion)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Specialised Training Completion\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))\n\n\n\n\n\n\n\nShow code\nEmployment_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Current_Employment_Status) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  Employment_dimension_summary,\n  digits = 2,                  \n  caption = \"Current Employment Status: Mean DRA Dimension Scores\"\n)\n\n\n\nCurrent Employment Status: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nCurrent_Employment_Status\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nFull_time\n39.63\n47.63\n39.16\n36.48\n27.93\n\n\nPart_time\n36.29\n70.42\n45.60\n37.88\n30.06\n\n\nTemporary_Contract\n35.13\n53.26\n38.01\n37.57\n29.29\n\n\nUnemployed\n28.71\n52.95\n39.06\n41.12\n29.98\n\n\n\n\n\nShow code\nEmployment_dimension_summary_long &lt;- Employment_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(Employment_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Current_Employment_Status)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Employment Status\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\n  \"Unemployed\"       = \"#7F8C8D\",     \n  \"Full_time\"      = \"#27AE60\",    \n  \"Part_time\" = \"#16A085\",  \n  \"Temporary_Contract\"    = \"#8E44AD\"      \n))\n\n\n\n\n\n\n\nShow code\nAH_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Absorbed_Host_Company) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  AH_dimension_summary,\n  digits = 2,                  \n  caption = \"Absorbed by Host Company: Mean DRA Dimension Scores\"\n)\n\n\n\nAbsorbed by Host Company: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nAbsorbed_Host_Company\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n34.44\n53.34\n39.20\n38.33\n30.82\n\n\nYes\n29.69\n59.16\n36.23\n39.06\n11.10\n\n\n\n\n\nShow code\nAH_dimension_summary_long &lt;- AH_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(AH_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Absorbed_Host_Company)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\ngeom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores - Absorbed by Host Company\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))\n\n\n\n\n\n\n\nShow code\nFS_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Further_Studies) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  FS_dimension_summary,\n  digits = 2,                  \n  caption = \"Further Studies: Mean DRA Dimension Scores\"\n)\n\n\n\nFurther Studies: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nFurther_Studies\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n34.38\n54.08\n39.17\n38.62\n28.46\n\n\nYes\n31.12\n50.60\n37.00\n35.96\n38.72\n\n\n\n\n\nShow code\nFS_dimension_summary_long &lt;- FS_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(FS_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Further_Studies)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Further Studies\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))\n\n\n\n\n\n\n\n\n\nSynthetic Minority Over-sampling Technique (SMOTE) was used to address class imbalances before additional analyses were performed. SMOTE identifies a minority sample, finds its ùëò-nearest neighbors, and generates new synthetic data points so that classes are equally represented.\n\n\nShow code\n# Each of the outcome variables is treated separately as the target for SMOTE.\n# After applying SMOTE for one target, you get a new balanced data set only for that target. Thus, you end up with five separate balanced data sets (one for each outcome variable).\n\n# Drop empty levels after filtering. \nsmote_data &lt;- raw_data %&gt;%\n  mutate(Current_Employment_Status = droplevels(Current_Employment_Status))\n\n\n\n\nShow code\n#  Apply SMOTE for each target variable separately\n# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n# 1. Placement_Contract_Completion \n\nset.seed(2025)\n\nbalanced_contract &lt;- smotenc(\n  df     = smote_data,                        # full data frame\n  var    = \"Placement_Contract_Completion\",   # target column name (must be factor)\n  k      = 5,                                            # nearest neighbors\n  over_ratio = 1                                         # 1 = balance to 1:1; &gt;1 oversamples minority more\n)\n\n# Check result\ntable(balanced_contract$Placement_Contract_Completion) / nrow(balanced_contract)\n\n\n\nIn progress          No         Yes \n  0.3333333   0.3333333   0.3333333 \n\n\nShow code\nkable(balanced_contract %&gt;%\n  dplyr::select(c(Placement_Contract_Completion)) %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nPlacement_Contract_Completion\ncount\n\n\n\n\nIn progress\n142\n\n\nNo\n142\n\n\nYes\n142\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_training &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Specialised_Training_Completion\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_training$Specialised_Training_Completion) / nrow(balanced_training)\n\n\n\n No Yes \n0.5 0.5 \n\n\nShow code\nkable(balanced_training %&gt;%\n  dplyr::select(c(Specialised_Training_Completion)) %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;%\n  dplyr::summarise(count = n()))\n\n\n\n\n\nSpecialised_Training_Completion\ncount\n\n\n\n\nNo\n180\n\n\nYes\n180\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_employment_status &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Current_Employment_Status\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_employment_status$Current_Employment_Status) / nrow(balanced_employment_status)\n\n\n\n         Full_time          Part_time Temporary_Contract         Unemployed \n              0.25               0.25               0.25               0.25 \n\n\nShow code\nkable(balanced_employment_status %&gt;%\n  dplyr::select(c(Current_Employment_Status)) %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nCurrent_Employment_Status\ncount\n\n\n\n\nFull_time\n118\n\n\nPart_time\n118\n\n\nTemporary_Contract\n118\n\n\nUnemployed\n118\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_studies &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Further_Studies\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_studies$Further_Studies) / nrow(balanced_studies)\n\n\n\n No Yes \n0.5 0.5 \n\n\nShow code\nkable(balanced_studies %&gt;%\n  dplyr::select(c(Further_Studies)) %&gt;% \n  group_by(Further_Studies) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nFurther_Studies\ncount\n\n\n\n\nNo\n197\n\n\nYes\n197\n\n\n\n\n\n\n\n\nLogistic regression models were used to examine the extent to which three DRA variables (i.e., predictors) could discriminate between two binary outcomes.\nTwo outcomes selected for this analysis:\n\nSpecialised Training Completion (Yes / No)\n\nFurther Studies (Yes / No)\n\n\n\nThe models use these three variables:\n\nComposite Risk Score\nPrinciples\n\nEmotional Understanding\n\nFor each outcome, the data were split into training (80%) and test (20%) sets using stratified sampling to maintain class proportions. Logistic regression models were fitted on the training data, and performance was evaluated on the held-out test set.\n\n\n\nAUC (Area Under the ROC Curve): Measures overall ability to rank candidates correctly. AUC = 0.5 means no discrimination (random guessing); AUC &gt; 0.7‚Äì0.8 is generally useful in applied settings.\nAccuracy: Overall % correct predictions (TP + TN) / total\nPrecision (for Yes): Of all candidates predicted to complete training / pursue further studies, what % were actually Yes? (TP / (TP + FP))\nRecall (for Yes): What proportion of actual Yes cases does the model correctly identify as Yes? Formula: TP / (TP + FN)\n\n\n\nShow code\npredictors &lt;- c(\"Composite_Risk_Score\", \"Principles\", \"Emotional_Understanding\") \n\nevaluate_binary_outcome &lt;- function(outcome) {\n  \n  cat(\"\\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\")\n  cat(\"Binary Outcome:\", outcome$name, \"\\n\")\n  cat(\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\\n\")\n  \n  df &lt;- outcome$data\n  target_var &lt;- outcome$name\n  pos &lt;- outcome$positive\n  neg &lt;- setdiff(levels(df[[target_var]]), pos)\n  \n  df[[target_var]] &lt;- as.factor(df[[target_var]])\n  \n  # Train/test split\n  set.seed(2025)\n  train_idx &lt;- createDataPartition(df[[target_var]], p = 0.8, list = FALSE)\n  train &lt;- df[train_idx, ]\n  test  &lt;- df[-train_idx, ]\n  \n  # Logistic regression\n  formula &lt;- as.formula(paste(target_var, \"~\", paste(predictors, collapse = \" + \")))\n  model &lt;- glm(formula, data = train, family = \"binomial\")\n  \n  # Predictions\n  pred_prob &lt;- predict(model, newdata = test, type = \"response\")\n  pred_class &lt;- factor(ifelse(pred_prob &gt;= 0.5, pos, neg), levels = c(neg, pos))\n  \n  # ROC\n  roc_obj &lt;- roc(\n    response  = test[[target_var]],\n    predictor = pred_prob,\n    levels    = c(neg, pos),\n    direction = \"&lt;\"\n  )\n  \n  # ggplot ROC\n  library(ggplot2)\n  p &lt;- ggroc(roc_obj, legacy.axes = TRUE) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"grey50\") +\n    labs(\n      title = paste(\"ROC Curve -\", outcome$name),\n      subtitle = paste(\"Positive class:\", pos),\n      x = \"1 - Specificity\",\n      y = \"Sensitivity\"\n    ) +\n    annotate(\"text\", x = 0.75, y = 0.25,\n             label = paste(\"AUC =\", round(auc(roc_obj), 3)),\n             size = 5, color = \"black\") +\n    theme_minimal(base_size = 13) +\n    coord_equal(ratio = 1)\n  \n  print(p)\n  \n  cat(\"AUC:\", round(auc(roc_obj), 3), \"\\n\\n\")\n  \n  # Confusion matrix\n  cm &lt;- conf_mat(\n    tibble(truth = test[[target_var]], estimate = pred_class),\n    truth = truth, estimate = estimate\n  )\n  \n# Extract the table \ntab &lt;- cm$table\n\n# Compute key metrics \ntn &lt;- tab[\"No\", \"No\"]\nfp &lt;- tab[\"Yes\", \"No\"]\nfn &lt;- tab[\"No\", \"Yes\"]\ntp &lt;- tab[\"Yes\", \"Yes\"]\n\ntotal &lt;- sum(tab)\naccuracy &lt;- (tp + tn) / total\nprecision &lt;- tp / (tp + fp)     # PPV for \"Yes\"\nrecall &lt;- tp / (tp + fn)        # sensitivity for \"Yes\"\nf1 &lt;- 2 * (precision * recall) / (precision + recall)\n\ncat(\"\\nConfusion Matrix:\\n\")\nprint(tab)\n\ncat(\"\\nAccuracy:   \", round(accuracy, 3), \"\\n\")\ncat(\"Precision:  \", round(precision, 3), \" (for Yes)\\n\")\ncat(\"Recall:     \", round(recall, 3), \" (for Yes)\\n\")\ncat(\"F1-score:   \", round(f1, 3), \"\\n\\n\")\n\n  invisible(list(model = model, roc = roc_obj, cm = cm, metrics = metrics))\n}\n\n\n\n\nShow code\n# Binary ones\nbinary_outcomes &lt;- list(\n  list(name = \"Specialised_Training_Completion\", \n       data = balanced_training, \n       positive = \"Yes\"),\n  list(name = \"Further_Studies\",                 \n       data = balanced_studies,   \n       positive = \"Yes\")\n)\n\n\nresults_binary &lt;- lapply(binary_outcomes, evaluate_binary_outcome)\n\n\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nBinary Outcome: Specialised_Training_Completion \n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n\n\n\n\nAUC: 0.529 \n\n\nConfusion Matrix:\n          Truth\nPrediction No Yes\n       No  15  14\n       Yes 21  22\n\nAccuracy:    0.514 \nPrecision:   0.512  (for Yes)\nRecall:      0.611  (for Yes)\nF1-score:    0.557 \n\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nBinary Outcome: Further_Studies \n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n\n\n\n\nAUC: 0.512 \n\n\nConfusion Matrix:\n          Truth\nPrediction No Yes\n       No  16  15\n       Yes 23  24\n\nAccuracy:    0.513 \nPrecision:   0.511  (for Yes)\nRecall:      0.615  (for Yes)\nF1-score:    0.558 \n\n\n\n\n\n\nAUC: 0.529 (near-random discrimination)\n\n\n\nAccuracy: 0.514 (correct classifications ~51%)\nPrecision (Yes): 0.512 ‚Äî Of predicted Yes, 51.2% were actual Yes\nRecall (Yes): 0.611 ‚Äî Caught 61.1% of actual Yes cases\nF1-score (Yes): 0.557 ‚Äî Balanced precision/recall\n\n\n\n\nThis shows how the model classified the test set (using 0.5 probability threshold). - True Negatives (TN): 15 candidates correctly predicted as No - False Negatives (FN): 14 candidates wrongly predicted as No (actually Yes) - False Positives (FP): 21 candidates wrongly predicted as Yes (actually No) - True Positives (TP): 22 candidates correctly predicted as Yes\nInsight: The model struggles to distinguish training completion. This outcome may depend more on programme factors than initial risk scores.\n\n\n\n\nAUC: 0.512 (near-random discrimination)\n\n\n\nAccuracy: 0.513 (correct classifications ~51%)\nPrecision (Yes): 0.511 ‚Äî Of predicted Yes, 51.1% were actual Yes\nRecall (Yes): 0.615 ‚Äî Caught 61.5% of actual Yes cases\nF1-score (Yes): 0.558 ‚Äî Balanced precision/recall\n\n\n\n\nThis shows how the model classified the test set (using 0.5 probability threshold). - True Negatives (TN): 16 candidates correctly predicted as No - False Negatives (FN): 15 candidates wrongly predicted as No (actually Yes) - False Positives (FP): 23 candidates wrongly predicted as Yes (actually No) - True Positives (TP): 24 candidates correctly predicted as Yes\nInsight: Similar to training completion, the three predictors explain almost nothing about whether employees pursue further studies.\nOverall ROC Insight: For these specific outcomes, the predictors (i.e., Principles, Emotional Understanding, and Composite Risk) showed limited discriminate ability and modest classification performance on the balanced test sets. Combining with other data (e.g., engagement metrics) could improve validity.\n\n\n\n\n\nFirst, a random forest model (2000 trees) was trained to predict Employment Status using the following predictors: Core Traits, Emotional Understanding, Judgement, Principles, Uncertainty, and Composite Risk Score.\n\n\nShow code\nbalanced_employment_status_RF_df &lt;- balanced_employment_status   \n\npredictors &lt;- c(\"Core_Traits\", \"Emotional_Understanding\", \"Judgement\", \"Principles\", \"Uncertainty\", \"Composite_Risk_Score\")  \n\n# Quick check\ncat(\"Number of predictors:\", length(predictors), \"\\n\")\n\n\nNumber of predictors: 6 \n\n\nShow code\ncat(\"Outcome levels:\", levels(balanced_employment_status_RF_df$Current_Employment_Status), \"\\n\\n\")\n\n\nOutcome levels: Full_time Part_time Temporary_Contract Unemployed \n\n\nShow code\nstr(balanced_employment_status_RF_df[, c(\"Current_Employment_Status\", head(predictors, 5))])\n\n\ntibble [472 √ó 6] (S3: tbl_df/tbl/data.frame)\n $ Current_Employment_Status: Factor w/ 4 levels \"Full_time\",\"Part_time\",..: 4 3 1 3 3 3 3 1 3 3 ...\n $ Core_Traits              : num [1:472] 4.22 25.8 3.31 7.7 12.93 ...\n $ Emotional_Understanding  : num [1:472] 6.92 23 94.2 25.17 17.73 ...\n $ Judgement                : num [1:472] 32.6 61.7 28.3 47.6 51.6 ...\n $ Principles               : num [1:472] 3.83 57.1 78.62 34.03 64.52 ...\n $ Uncertainty              : num [1:472] 0 52.9 52.9 0 0 ...\n\n\nShow code\n############################################################\n# Train / test split (70 / 30) \n############################################################\nset.seed(2025)\n\ntrain_index &lt;- createDataPartition(\n  balanced_employment_status_RF_df$Current_Employment_Status, \n  p = 0.7, \n  list = FALSE\n)\n\ntrain_data &lt;- balanced_employment_status_RF_df[train_index, ]\ntest_data  &lt;- balanced_employment_status_RF_df[-train_index, ]\n\ncat(\"Training set rows:\", nrow(train_data), \"\\n\")\n\n\nTraining set rows: 332 \n\n\nShow code\ncat(\"Test set rows:    \", nrow(test_data), \"\\n\\n\")\n\n\nTest set rows:     140 \n\n\nShow code\n############################################################\n# Fit Random Forest model (multi-class)\n############################################################\nrf_model &lt;- randomForest(\n  x = train_data[, predictors],          \n  y = train_data$Current_Employment_Status,\n  ntree = 2000,                             # number of trees\n  mtry = floor(sqrt(length(predictors))),   # default for classification\n  importance = TRUE,                        # for variable importance\n  proximity = FALSE,                     \n  na.action = na.roughfix                \n)\n\n# Print model summary\nprint(rf_model)\n\n\n\nCall:\n randomForest(x = train_data[, predictors], y = train_data$Current_Employment_Status,      ntree = 2000, mtry = floor(sqrt(length(predictors))), importance = TRUE,      proximity = FALSE, na.action = na.roughfix) \n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 36.14%\nConfusion matrix:\n                   Full_time Part_time Temporary_Contract Unemployed\nFull_time                 66         8                  6          3\nPart_time                  2        72                  4          5\nTemporary_Contract        15        11                 32         25\nUnemployed                12        12                 17         42\n                   class.error\nFull_time            0.2048193\nPart_time            0.1325301\nTemporary_Contract   0.6144578\nUnemployed           0.4939759\n\n\nShow code\n############################################################\n# Predictions on test data\n############################################################\nrf_pred_class &lt;- predict(rf_model, newdata = test_data[, predictors])\n\nrf_pred_prob &lt;- predict(\n  rf_model,\n  newdata = test_data[, predictors],\n  type = \"prob\"\n)\n\n############################################################\n# Confusion matrix & performance metrics\n############################################################\ncm_caret &lt;- confusionMatrix(\n  data      = rf_pred_class,\n  reference = test_data$Current_Employment_Status\n)\n\nprint(cm_caret)\n\n\nConfusion Matrix and Statistics\n\n                    Reference\nPrediction           Full_time Part_time Temporary_Contract Unemployed\n  Full_time                 24         4                  6          6\n  Part_time                  4        30                  7          1\n  Temporary_Contract         3         0                 14          6\n  Unemployed                 4         1                  8         22\n\nOverall Statistics\n                                         \n               Accuracy : 0.6429         \n                 95% CI : (0.5575, 0.722)\n    No Information Rate : 0.25           \n    P-Value [Acc &gt; NIR] : &lt;2e-16         \n                                         \n                  Kappa : 0.5238         \n                                         \n Mcnemar's Test P-Value : 0.192          \n\nStatistics by Class:\n\n                     Class: Full_time Class: Part_time\nSensitivity                    0.6857           0.8571\nSpecificity                    0.8476           0.8857\nPos Pred Value                 0.6000           0.7143\nNeg Pred Value                 0.8900           0.9490\nPrevalence                     0.2500           0.2500\nDetection Rate                 0.1714           0.2143\nDetection Prevalence           0.2857           0.3000\nBalanced Accuracy              0.7667           0.8714\n                     Class: Temporary_Contract Class: Unemployed\nSensitivity                             0.4000            0.6286\nSpecificity                             0.9143            0.8762\nPos Pred Value                          0.6087            0.6286\nNeg Pred Value                          0.8205            0.8762\nPrevalence                              0.2500            0.2500\nDetection Rate                          0.1000            0.1571\nDetection Prevalence                    0.1643            0.2500\nBalanced Accuracy                       0.6571            0.7524\n\n\nShow code\n# Overall accuracy\ncat(\"\\nOverall Accuracy:\", round(cm_caret$overall[\"Accuracy\"], 3), \"\\n\")\n\n\n\nOverall Accuracy: 0.643 \n\n\nShow code\n# Per-class precision, recall, F1 \ncat(\"\\nPer-class metrics:\\n\")\n\n\n\nPer-class metrics:\n\n\nShow code\nprint(cm_caret$byClass[, c(\"Precision\", \"Recall\", \"F1\")])\n\n\n                          Precision    Recall        F1\nClass: Full_time          0.6000000 0.6857143 0.6400000\nClass: Part_time          0.7142857 0.8571429 0.7792208\nClass: Temporary_Contract 0.6086957 0.4000000 0.4827586\nClass: Unemployed         0.6285714 0.6285714 0.6285714\n\n\nShow code\n# Macro-averaged metrics (simple average across classes)\nmacro_precision &lt;- mean(cm_caret$byClass[, \"Precision\"], na.rm = TRUE)\nmacro_recall    &lt;- mean(cm_caret$byClass[, \"Recall\"], na.rm = TRUE)\nmacro_f1        &lt;- mean(cm_caret$byClass[, \"F1\"], na.rm = TRUE)\n\ncat(\"\\nMacro-averaged:\\n\")\n\n\n\nMacro-averaged:\n\n\nShow code\ncat(\"Precision:\", round(macro_precision, 3), \"\\n\")\n\n\nPrecision: 0.638 \n\n\nShow code\ncat(\"Recall:   \", round(macro_recall,    3), \"\\n\")\n\n\nRecall:    0.643 \n\n\nShow code\ncat(\"F1:       \", round(macro_f1,        3), \"\\n\")\n\n\nF1:        0.633 \n\n\nShow code\n############################################################\n# Multi-class AUC (macro-averaged)\n############################################################\nmulti_auc &lt;- multiclass.roc(\n  response  = test_data$Current_Employment_Status,\n  predictor = rf_pred_prob\n)\n\ncat(\"\\nMulti-class AUC (macro-averaged):\", round(auc(multi_auc), 3), \"\\n\")\n\n\n\nMulti-class AUC (macro-averaged): 0.875 \n\n\nShow code\n############################################################\n# Variable importance\n############################################################\ncat(\"\\nVariable Importance (MeanDecreaseGini):\\n\")\n\n\n\nVariable Importance (MeanDecreaseGini):\n\n\nShow code\nimportance(rf_model) %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"Predictor\") %&gt;%\n  arrange(desc(MeanDecreaseGini)) %&gt;%\n  head(15) %&gt;%               # top 15\n  print()\n\n\n                Predictor Full_time Part_time Temporary_Contract Unemployed\n1 Emotional_Understanding  89.30430  98.76786         11.9130505   23.82122\n2              Principles  71.66467  73.81713          5.6151620   34.65674\n3    Composite_Risk_Score  66.43196  62.26855         -0.8070441   47.36499\n4             Core_Traits  62.68984  53.81674         -5.4520896   33.14145\n5               Judgement  50.70257  62.13475         -1.9497412   16.89340\n6             Uncertainty  39.98729  56.67910          1.4615802   23.09460\n  MeanDecreaseAccuracy MeanDecreaseGini\n1            111.17026         51.07874\n2             90.07002         47.53747\n3             88.58889         46.47894\n4             71.82570         40.47700\n5             70.54355         39.95138\n6             60.60349         22.74974\n\n\nShow code\n# Plot\nvarImpPlot(rf_model, main = \"Random Forest Variable Importance - Current Employment Status\")\n\n\n\n\n\nCore Traits and Emotional Understanding are the strongest predictors of Employment Status. Uncertainty is the weakest predictor.\nA second random forest model (2000 trees) was trained to predict Work Placement Contract Completion using the following predictors: Core Traits, Emotional Understanding, Judgement, Principles, Uncertainty, and Composite Risk Score.\n\n\nShow code\n# Random Forests for Work_Placement_Contract \n\nbalanced_contract_RF_df &lt;- balanced_contract  \n\npredictors &lt;- c(\"Core_Traits\", \"Emotional_Understanding\", \"Judgement\", \"Principles\", \"Uncertainty\", \"Composite_Risk_Score\")  \n\n# Quick check\ncat(\"Number of predictors:\", length(predictors), \"\\n\")\n\n\nNumber of predictors: 6 \n\n\nShow code\ncat(\"Outcome levels:\", levels(balanced_contract_RF_df$Placement_Contract_Completion), \"\\n\\n\")\n\n\nOutcome levels: In progress No Yes \n\n\nShow code\nstr(balanced_contract_RF_df[, c(\"Placement_Contract_Completion\", head(predictors, 5))])\n\n\ntibble [426 √ó 6] (S3: tbl_df/tbl/data.frame)\n $ Placement_Contract_Completion: Factor w/ 3 levels \"In progress\",..: 1 3 3 1 2 1 3 3 3 3 ...\n $ Core_Traits                  : num [1:426] 4.22 25.8 3.31 7.7 12.93 ...\n $ Emotional_Understanding      : num [1:426] 6.92 23 94.2 25.17 17.73 ...\n $ Judgement                    : num [1:426] 32.6 61.7 28.3 47.6 51.6 ...\n $ Principles                   : num [1:426] 3.83 57.1 78.62 34.03 64.52 ...\n $ Uncertainty                  : num [1:426] 0 52.9 52.9 0 0 ...\n\n\nShow code\n############################################################\n# Train / test split (70 / 30) \n############################################################\nset.seed(2025)\n\ntrain_index &lt;- createDataPartition(\n  balanced_contract_RF_df$Placement_Contract_Completion, \n  p = 0.7, \n  list = FALSE\n)\n\ntrain_data &lt;- balanced_contract_RF_df[train_index, ]\ntest_data  &lt;- balanced_contract_RF_df[-train_index, ]\n\ncat(\"Training set rows:\", nrow(train_data), \"\\n\")\n\n\nTraining set rows: 300 \n\n\nShow code\ncat(\"Test set rows:    \", nrow(test_data), \"\\n\\n\")\n\n\nTest set rows:     126 \n\n\nShow code\n############################################################\n# Fit Random Forest model (multi-class)\n############################################################\nrf_model &lt;- randomForest(\n  x = train_data[, predictors],          \n  y = train_data$Placement_Contract_Completion,\n  ntree = 2000,                             # number of trees\n  mtry = floor(sqrt(length(predictors))),   # default for classification\n  importance = TRUE,                        # for variable importance\n  proximity = FALSE,                     \n  na.action = na.roughfix                \n)\n\n# Print model summary\nprint(rf_model)\n\n\n\nCall:\n randomForest(x = train_data[, predictors], y = train_data$Placement_Contract_Completion,      ntree = 2000, mtry = floor(sqrt(length(predictors))), importance = TRUE,      proximity = FALSE, na.action = na.roughfix) \n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 27.33%\nConfusion matrix:\n            In progress No Yes class.error\nIn progress          69 11  20        0.31\nNo                    6 84  10        0.16\nYes                  23 12  65        0.35\n\n\nShow code\n############################################################\n# Predictions on test data\n############################################################\nrf_pred_class &lt;- predict(rf_model, newdata = test_data[, predictors])\n\nrf_pred_prob &lt;- predict(\n  rf_model,\n  newdata = test_data[, predictors],\n  type = \"prob\"\n)\n\n############################################################\n# Confusion matrix & performance metrics\n############################################################\ncm_caret &lt;- confusionMatrix(\n  data      = rf_pred_class,\n  reference = test_data$Placement_Contract_Completion\n)\n\nprint(cm_caret)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    In progress No Yes\n  In progress          29  3  14\n  No                    3 33   5\n  Yes                  10  6  23\n\nOverall Statistics\n                                          \n               Accuracy : 0.6746          \n                 95% CI : (0.5854, 0.7554)\n    No Information Rate : 0.3333          \n    P-Value [Acc &gt; NIR] : 5.529e-15       \n                                          \n                  Kappa : 0.5119          \n                                          \n Mcnemar's Test P-Value : 0.8596          \n\nStatistics by Class:\n\n                     Class: In progress Class: No Class: Yes\nSensitivity                      0.6905    0.7857     0.5476\nSpecificity                      0.7976    0.9048     0.8095\nPos Pred Value                   0.6304    0.8049     0.5897\nNeg Pred Value                   0.8375    0.8941     0.7816\nPrevalence                       0.3333    0.3333     0.3333\nDetection Rate                   0.2302    0.2619     0.1825\nDetection Prevalence             0.3651    0.3254     0.3095\nBalanced Accuracy                0.7440    0.8452     0.6786\n\n\nShow code\n# Overall accuracy\ncat(\"\\nOverall Accuracy:\", round(cm_caret$overall[\"Accuracy\"], 3), \"\\n\")\n\n\n\nOverall Accuracy: 0.675 \n\n\nShow code\n# Per-class precision, recall, F1 \ncat(\"\\nPer-class metrics:\\n\")\n\n\n\nPer-class metrics:\n\n\nShow code\nprint(cm_caret$byClass[, c(\"Precision\", \"Recall\", \"F1\")])\n\n\n                   Precision    Recall        F1\nClass: In progress 0.6304348 0.6904762 0.6590909\nClass: No          0.8048780 0.7857143 0.7951807\nClass: Yes         0.5897436 0.5476190 0.5679012\n\n\nShow code\n# Macro-averaged metrics (simple average across classes)\nmacro_precision &lt;- mean(cm_caret$byClass[, \"Precision\"], na.rm = TRUE)\nmacro_recall    &lt;- mean(cm_caret$byClass[, \"Recall\"], na.rm = TRUE)\nmacro_f1        &lt;- mean(cm_caret$byClass[, \"F1\"], na.rm = TRUE)\n\ncat(\"\\nMacro-averaged:\\n\")\n\n\n\nMacro-averaged:\n\n\nShow code\ncat(\"Precision:\", round(macro_precision, 3), \"\\n\")\n\n\nPrecision: 0.675 \n\n\nShow code\ncat(\"Recall:   \", round(macro_recall,    3), \"\\n\")\n\n\nRecall:    0.675 \n\n\nShow code\ncat(\"F1:       \", round(macro_f1,        3), \"\\n\")\n\n\nF1:        0.674 \n\n\nShow code\n############################################################\n# Multi-class AUC (macro-averaged)\n############################################################\nmulti_auc &lt;- multiclass.roc(\n  response  = test_data$Placement_Contract_Completion,\n  predictor = rf_pred_prob\n)\n\ncat(\"\\nMulti-class AUC (macro-averaged):\", round(auc(multi_auc), 3), \"\\n\")\n\n\n\nMulti-class AUC (macro-averaged): 0.847 \n\n\nShow code\n############################################################\n# Variable importance\n############################################################\ncat(\"\\nVariable Importance (MeanDecreaseGini):\\n\")\n\n\n\nVariable Importance (MeanDecreaseGini):\n\n\nShow code\nimportance(rf_model) %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"Predictor\") %&gt;%\n  arrange(desc(MeanDecreaseGini)) %&gt;%\n  head(15) %&gt;%               # top 15\n  print()\n\n\n                Predictor In progress       No       Yes MeanDecreaseAccuracy\n1             Core_Traits    44.61575 88.98770 16.066408             86.06533\n2 Emotional_Understanding    54.07565 73.78543 34.761558             87.00799\n3              Principles    47.78354 81.97185  9.275946             80.24299\n4               Judgement    33.48851 45.19150 13.086894             53.07396\n5    Composite_Risk_Score    30.32766 56.88619  3.774848             57.22316\n6             Uncertainty    22.22296 51.93331 16.833642             52.50164\n  MeanDecreaseGini\n1         41.04164\n2         40.51270\n3         37.21400\n4         31.54092\n5         29.72965\n6         19.30408\n\n\nShow code\n# Plot\nvarImpPlot(rf_model, main = \"Random Forest Variable Importance - Placement Contract Completion\")\n\n\n\n\n\nCore Traits and Emotional Understanding are the strongest drivers of whether someone completes their placement contract, is still in progress, or does not complete it. Uncertainty contributes the least."
  },
  {
    "objectID": "psychometrics-candidate-outcomes.html#descriptive-statistics",
    "href": "psychometrics-candidate-outcomes.html#descriptive-statistics",
    "title": "psychometrics-candidate-outcomes",
    "section": "",
    "text": "This section provides an overview of the simulated data, including correlations among DRA dimensions and risk scores, outlier detection, and group comparisons across key outcomes.\n\n\nThe Spearman correlations show strong interrelationships among the DRA dimensions and risk components:\n\nRisk Mitigators shows a strong, negative association with Risk Drivers (-0.77, p&lt;0.001), as expected in the assessment design.\nSimilarly, the Composite Risk Score shows a strong, positive correlation with Risk Drivers (0.92, p&lt;0.001) and a strong negative correlation with Risk Mitigators (-0.95, p&lt;0.001).\n\nWeak or non-significant correlations (e.g., Uncertainty with Principles, r=0.00) highlight independent aspects of the profile.\n\n\nShow code\ncorrelations &lt;- raw_data %&gt;% \n  dplyr::select(c(1:8))\n\nflattenCorrMatrix &lt;- function(cormat, pmat) {\n  ut &lt;- upper.tri(cormat)\n  data.frame(\n    row=rownames(cormat)[row(cormat)[ut]],\n    column=rownames(cormat)[col(cormat)[ut]],\n    cor=(cormat)[ut],\n    p=pmat[ut]\n  )\n}\n\ncor_sig &lt;- Hmisc::rcorr(as.matrix(correlations), type = \"spearman\") \n\ncorrelation_table &lt;- flattenCorrMatrix(cor_sig$r, cor_sig$P) %&gt;%\n  mutate(\n    cor = round(cor, 3),   \n    p   = round(p, 3)       \n  ) \n\ncorrelation_table %&gt;%\n  mutate(\n    cor = round(cor, 3),\n    p   = round(p, 3),\n    ` ` = case_when(p &lt; 0.001 ~ \"***\", p &lt; 0.01 ~ \"**\", p &lt; 0.05 ~ \"*\", TRUE ~ \"\")\n  ) %&gt;%\n  select(`Variable 1` = row, `Variable 2` = column, Correlation = cor, `p-value` = p, Significance = ` `) %&gt;%\n  kable(\n    caption = \"Spearman Correlations (significant p &lt; 0.05)\",\n    digits  = 3,\n    align   = c(\"l\", \"l\", \"r\", \"r\", \"c\")\n  )\n\n\n\nSpearman Correlations (significant p &lt; 0.05)\n\n\n\n\n\n\n\n\n\nVariable 1\nVariable 2\nCorrelation\np-value\nSignificance\n\n\n\n\nCore_Traits\nEmotional_Understanding\n-0.230\n0.001\n**\n\n\nCore_Traits\nJudgement\n0.262\n0.000\n***\n\n\nEmotional_Understanding\nJudgement\n-0.018\n0.792\n\n\n\nCore_Traits\nPrinciples\n0.171\n0.011\n*\n\n\nEmotional_Understanding\nPrinciples\n0.093\n0.172\n\n\n\nJudgement\nPrinciples\n0.152\n0.025\n*\n\n\nCore_Traits\nUncertainty\n0.044\n0.521\n\n\n\nEmotional_Understanding\nUncertainty\n-0.098\n0.149\n\n\n\nJudgement\nUncertainty\n0.443\n0.000\n***\n\n\nPrinciples\nUncertainty\n0.003\n0.960\n\n\n\nCore_Traits\nRisk_Mitigators\n-0.683\n0.000\n***\n\n\nEmotional_Understanding\nRisk_Mitigators\n-0.183\n0.007\n**\n\n\nJudgement\nRisk_Mitigators\n-0.380\n0.000\n***\n\n\nPrinciples\nRisk_Mitigators\n-0.502\n0.000\n***\n\n\nUncertainty\nRisk_Mitigators\n-0.085\n0.211\n\n\n\nCore_Traits\nRisk_Drivers\n0.593\n0.000\n***\n\n\nEmotional_Understanding\nRisk_Drivers\n0.329\n0.000\n***\n\n\nJudgement\nRisk_Drivers\n0.353\n0.000\n***\n\n\nPrinciples\nRisk_Drivers\n0.539\n0.000\n***\n\n\nUncertainty\nRisk_Drivers\n-0.025\n0.719\n\n\n\nRisk_Mitigators\nRisk_Drivers\n-0.766\n0.000\n***\n\n\nCore_Traits\nComposite_Risk_Score\n0.683\n0.000\n***\n\n\nEmotional_Understanding\nComposite_Risk_Score\n0.255\n0.000\n***\n\n\nJudgement\nComposite_Risk_Score\n0.396\n0.000\n***\n\n\nPrinciples\nComposite_Risk_Score\n0.544\n0.000\n***\n\n\nUncertainty\nComposite_Risk_Score\n0.029\n0.673\n\n\n\nRisk_Mitigators\nComposite_Risk_Score\n-0.952\n0.000\n***\n\n\nRisk_Drivers\nComposite_Risk_Score\n0.915\n0.000\n***\n\n\n\n\n\n\n\nShow code\nmodel.matrix(~0+., correlations) %&gt;% \n  cor(use='pairwise.complete.obs', method = \"spearman\") %&gt;% \n  ggcorrplot(sig.level=0.5, \n             hc.order = TRUE, \n             show.diag = FALSE, \n             type = \"lower\", \n             lab_size=0.5) +\n  xlab(\"Variable 1\") + \n  ylab(\"Variable 2\") +\n  theme_apa(legend.pos = \"right\", legend.use.title = FALSE,\n  legend.font.size = 12, x.font.size = 12, y.font.size = 12,\n  facet.title.size = 12, remove.y.gridlines = TRUE,\n  remove.x.gridlines = TRUE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\n‚Ñπ Please use tidy evaluation idioms with `aes()`.\n‚Ñπ See also `vignette(\"ggplot2-in-packages\")` for more information.\n‚Ñπ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n\n\nShow code\n# Detecting outliers using the IQR method \n\nQ1 &lt;- quantile(raw_data$Composite_Risk_Score, 0.25)\nQ3 &lt;- quantile(raw_data$Composite_Risk_Score, 0.75)\nIQR &lt;- Q3 - Q1\noutliers &lt;- which(raw_data$Composite_Risk_Score&lt; (Q1 - 1.5 * IQR) | raw_data$Composite_Risk_Score &gt; (Q3 + 1.5 * IQR))\n\nif (length(outliers) &gt; 0) {\n  # Extract the values of outliers\n  outlier_values &lt;- raw_data$Composite_Risk_Score[outliers]\n\n  # Print values\n  print(raw_data)\n} else {\n  print(\"No outliers were found using the IQR method.\")\n}\n\n\n[1] \"No outliers were found using the IQR method.\"\n\n\nNo outliers were detected in the Composite Risk Score using the IQR method, suggesting the data is free from extreme values that could skew results.\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Work_Readiness_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Work_Readiness_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Work Readiness Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nWork Readiness Completion\n\n\nWork_Readiness_Completion\nCount\nPercentage\n\n\n\n\nYes\n217\n100%\n\n\n\n\n\nSince all 217 candidates completed the work readiness assessment, this variable was excluded for predictive analysis.\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Placement_Contract_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Placement_Contract_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Placement Contract Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nPlacement Contract Completion\n\n\nPlacement_Contract_Completion\nCount\nPercentage\n\n\n\n\nIn progress\n51\n23.5%\n\n\nNo\n24\n11.1%\n\n\nYes\n142\n65.4%\n\n\n\n\n\nThe majority (65.7%) completed their placement contract, with 23.1% still in progress and 11.1% not completing.\n\n\nShow code\nPlacement_Contract_Completion_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Placement_Contract_Completion, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Placement_Contract_Completion_Means)\n\n\n\n\n\nPlacement_Contract_Completion\nMean_Composite_Risk\n\n\n\n\nIn progress\n31.49\n\n\nYes\n34.05\n\n\nNo\n36.06\n\n\n\n\n\nEmployees who are still completing their placement contract had the lowest average composite risk score (31.49) whereas employees who did not complete their placement contracts had the highest average composite risk score (36.06).\n\n\nShow code\nggplot(raw_data, \n       aes(x = Placement_Contract_Completion,\n           y = Composite_Risk_Score, \n           fill = Placement_Contract_Completion)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score by Placement Contract Completion\",\n       x = \"Placement Contract Completion\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"In progress\" = \"orange\", \"No\" = \"red\", \n                               \"Yes\" = \"lightgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Specialised_Training_Completion) %&gt;%\n  na.omit() %&gt;%\n  group_by(Specialised_Training_Completion) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Specialised Training Completion\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nSpecialised Training Completion\n\n\nSpecialised_Training_Completion\nCount\nPercentage\n\n\n\n\nNo\n36\n16.6%\n\n\nYes\n181\n83.4%\n\n\n\n\n\nMost candidates (83.4%) completed specialised training.\n\n\nShow code\nSpecialised_Training_Completion_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Specialised_Training_Completion, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Specialised_Training_Completion_Means)\n\n\n\n\n\nSpecialised_Training_Completion\nMean_Composite_Risk\n\n\n\n\nYes\n32.45\n\n\nNo\n39.81\n\n\n\n\n\nEmployees who completed specialized training had a lower average composite risk score compared to those who did not.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Specialised_Training_Completion,\n           y = Composite_Risk_Score, \n           fill = Specialised_Training_Completion)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score by Specialised Training Completion\",\n       x = \"Specialised Training Completion\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"lightgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Current_Employment_Status) %&gt;%\n  na.omit() %&gt;%\n  group_by(Current_Employment_Status) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Current Employment Status\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nCurrent Employment Status\n\n\nCurrent_Employment_Status\nCount\nPercentage\n\n\n\n\nFull_time\n26\n12%\n\n\nPart_time\n16\n7.4%\n\n\nSelf_employed\n1\n0.5%\n\n\nTemporary_Contract\n118\n54.4%\n\n\nUnemployed\n56\n25.8%\n\n\n\n\n\nThe most common employment status is Temporary Contract (54.4%), followed by Unemployed (25.8%). Self employed was excluded due to rarity (n=1) resulting in a sample size of 216.\n\n\nShow code\nraw_data &lt;- raw_data %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  filter(Current_Employment_Status != \"Self_employed\") %&gt;% \n  ungroup()\n  \nCurrent_Employment_Status_Means &lt;- raw_data %&gt;%\n  ungroup() %&gt;% \n  dplyr::select(c(Current_Employment_Status, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  filter(Current_Employment_Status != \"Self_employed\") %&gt;% \n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Current_Employment_Status_Means)\n\n\n\n\n\nCurrent_Employment_Status\nMean_Composite_Risk\n\n\n\n\nUnemployed\n28.59\n\n\nTemporary_Contract\n34.59\n\n\nFull_time\n37.94\n\n\nPart_time\n38.52\n\n\n\n\n\nEmployees with part-time contracts have the highest average composite risk (38.52), while candidates who are currently unemployed have the lowest (28.59).\n\n\nShow code\nggplot(raw_data, \n       aes(x = Current_Employment_Status,\n           y = Composite_Risk_Score, \n           fill = Current_Employment_Status)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of Composite Risk Score by Current Employment Status\",\n       x = \"Current Employment Status\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Unemployed\" = \"red\", \n                               \"Full_time\" = \"darkgreen\", \n                               \"Part_time\" = \"gold\",\n                               \"Temporary_Contract\" = \"darkorange\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Absorbed_Host_Company) %&gt;%\n  na.omit() %&gt;%\n  group_by(Absorbed_Host_Company) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Absorbed by Host Company\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nAbsorbed by Host Company\n\n\nAbsorbed_Host_Company\nCount\nPercentage\n\n\n\n\nNo\n200\n92.6%\n\n\nYes\n16\n7.4%\n\n\n\n\n\nOnly 7.4% of employees were absorbed by their respective host company. However, this variable is likely skewed because the economy is saturated and businesses cannot accommodate more employees rendering this criterion relatively less useful for prediction.\n\n\nShow code\nAbsorbed_Host_Company_Means &lt;- raw_data %&gt;%\n  ungroup() %&gt;% \n  dplyr::select(c(Absorbed_Host_Company, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Absorbed_Host_Company) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Absorbed_Host_Company_Means)\n\n\n\n\n\nAbsorbed_Host_Company\nMean_Composite_Risk\n\n\n\n\nNo\n33.49\n\n\nYes\n36.68\n\n\n\n\n\nEmployees who were absorbed by their host company had a slightly higher average composite risk score.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Absorbed_Host_Company,\n           y = Composite_Risk_Score, \n           fill = Absorbed_Host_Company)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score\",\n       x = \"Absorbed by Host Company\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"darkgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nraw_data %&gt;%\n  dplyr::select(Further_Studies) %&gt;%\n  na.omit() %&gt;%\n  group_by(Further_Studies) %&gt;%\n  summarise(Count = n()) %&gt;%\n  ungroup() %&gt;%                    \n  mutate(\n    Percentage = round(Count / sum(Count) * 100, 1),\n    Percentage = paste0(Percentage, \"%\")\n  ) %&gt;%\n  kable(\n    caption = \"Further Studies\",\n    align = c(\"l\", \"r\", \"r\")\n  )\n\n\n\nFurther Studies\n\n\nFurther_Studies\nCount\nPercentage\n\n\n\n\nNo\n197\n91.2%\n\n\nYes\n19\n8.8%\n\n\n\n\n\nOnly 8.8% pursued further studies however this is likely influenced by various external factors such as age, current level of education, and affordability.\n\n\nShow code\nFurther_Studies_Means &lt;- raw_data %&gt;%\n  dplyr::select(c(Further_Studies, Composite_Risk_Score)) %&gt;% \n  na.omit() %&gt;% \n  group_by(Further_Studies) %&gt;%\n  summarise(Mean_Composite_Risk = mean(Composite_Risk_Score)) %&gt;% \n  arrange(Mean_Composite_Risk) %&gt;%\n  dplyr::mutate(Mean_Composite_Risk = round(Mean_Composite_Risk, 2))\n\nkable(Further_Studies_Means)\n\n\n\n\n\nFurther_Studies\nMean_Composite_Risk\n\n\n\n\nYes\n28.51\n\n\nNo\n34.23\n\n\n\n\n\nLower risk is linked to continued education, suggesting the DRA can identify motivated, resilient candidates likely to seek growth opportunities.\n\n\nShow code\nggplot(raw_data, \n       aes(x = Further_Studies,\n           y = Composite_Risk_Score, \n           fill = Further_Studies)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16) +\n  labs(title = \"Distribution of DRA Composite Risk Score\",\n       x = \"Further Studies\",\n       y = \"Composite Risk Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"red\", \n                               \"Yes\" = \"darkgreen\"))\n\n\n\n\n\n\n\n\n\n\nShow code\nPC_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  PC_dimension_summary,\n  digits = 2,                  \n  caption = \"Placement Contract Completion: Mean DRA Dimension Scores\"\n)\n\n\n\nPlacement Contract Completion: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nPlacement_Contract_Completion\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nIn progress\n34.46\n50.40\n43.50\n39.73\n29.32\n\n\nNo\n46.46\n42.51\n42.85\n30.16\n26.23\n\n\nYes\n31.87\n56.87\n36.73\n39.30\n29.90\n\n\n\n\n\nShow code\nPC_dimension_summary_long &lt;- PC_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(PC_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Placement_Contract_Completion)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Placement Contract Completion\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\n  \"No\"       = \"#7F8C8D\",     \n  \"Yes\"      = \"#27AE60\",     \n  \"In progress\" = \"#16A085\"  \n))\n\n\n\n\n\n\n\nShow code\nSTC_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  STC_dimension_summary,\n  digits = 2,                  \n  caption = \"Specialised Training Completion: Mean DRA Dimension Scores\"\n)\n\n\n\nSpecialised Training Completion: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nSpecialised_Training_Completion\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n39.84\n50.83\n41.13\n39.63\n38.06\n\n\nYes\n32.94\n54.36\n38.55\n38.13\n27.62\n\n\n\n\n\nShow code\nSTC_dimension_summary_long &lt;- STC_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(STC_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Specialised_Training_Completion)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Specialised Training Completion\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))\n\n\n\n\n\n\n\nShow code\nEmployment_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Current_Employment_Status) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  Employment_dimension_summary,\n  digits = 2,                  \n  caption = \"Current Employment Status: Mean DRA Dimension Scores\"\n)\n\n\n\nCurrent Employment Status: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nCurrent_Employment_Status\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nFull_time\n39.63\n47.63\n39.16\n36.48\n27.93\n\n\nPart_time\n36.29\n70.42\n45.60\n37.88\n30.06\n\n\nTemporary_Contract\n35.13\n53.26\n38.01\n37.57\n29.29\n\n\nUnemployed\n28.71\n52.95\n39.06\n41.12\n29.98\n\n\n\n\n\nShow code\nEmployment_dimension_summary_long &lt;- Employment_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(Employment_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Current_Employment_Status)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Employment Status\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\n  \"Unemployed\"       = \"#7F8C8D\",     \n  \"Full_time\"      = \"#27AE60\",    \n  \"Part_time\" = \"#16A085\",  \n  \"Temporary_Contract\"    = \"#8E44AD\"      \n))\n\n\n\n\n\n\n\nShow code\nAH_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Absorbed_Host_Company) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  AH_dimension_summary,\n  digits = 2,                  \n  caption = \"Absorbed by Host Company: Mean DRA Dimension Scores\"\n)\n\n\n\nAbsorbed by Host Company: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nAbsorbed_Host_Company\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n34.44\n53.34\n39.20\n38.33\n30.82\n\n\nYes\n29.69\n59.16\n36.23\n39.06\n11.10\n\n\n\n\n\nShow code\nAH_dimension_summary_long &lt;- AH_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(AH_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Absorbed_Host_Company)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\ngeom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores - Absorbed by Host Company\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))\n\n\n\n\n\n\n\nShow code\nFS_dimension_summary &lt;- raw_data %&gt;% \n  group_by(Further_Studies) %&gt;% \n  summarise(\n    `Core Traits` = mean(Core_Traits, na.rm = TRUE),\n    `Emotional Understanding` = mean(Emotional_Understanding, na.rm = TRUE),\n    `Judgement` = mean(Judgement, na.rm = TRUE),\n    `Principles` = mean(Principles, na.rm = TRUE),\n    `Uncertainty` = mean(Uncertainty, na.rm = TRUE)\n    )\n\nkable(\n  FS_dimension_summary,\n  digits = 2,                  \n  caption = \"Further Studies: Mean DRA Dimension Scores\"\n)\n\n\n\nFurther Studies: Mean DRA Dimension Scores\n\n\n\n\n\n\n\n\n\n\nFurther_Studies\nCore Traits\nEmotional Understanding\nJudgement\nPrinciples\nUncertainty\n\n\n\n\nNo\n34.38\n54.08\n39.17\n38.62\n28.46\n\n\nYes\n31.12\n50.60\n37.00\n35.96\n38.72\n\n\n\n\n\nShow code\nFS_dimension_summary_long &lt;- FS_dimension_summary %&gt;%\n  pivot_longer(cols = c(2:6), \n               names_to = \"Dimensions\",   \n               values_to = \"Mean_Score\") %&gt;% \n  dplyr::mutate(Dimensions = as.factor(Dimensions))\n\nggplot(FS_dimension_summary_long, aes(x = Dimensions, y = Mean_Score, fill = Further_Studies)) +\ngeom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(\n    aes(label = round(Mean_Score, 2)),\n    position = position_dodge(width = 0.9),\n    vjust = -0.2, size = 3.2, color = \"black\"\n  ) + \nlabs(x = \"DRA Dimensions\", y = \"Mean Risk Score\", title = \"Mean DRA Dimension Risk Scores by Further Studies\") + \ntheme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), \n        axis.text.x = element_text(angle = 45, hjust = 1)) + \n  scale_fill_manual(values = c(\"No\" = \"#7F8C8D\", \"Yes\" = \"#27AE60\"))"
  },
  {
    "objectID": "psychometrics-candidate-outcomes.html#smote-sampling",
    "href": "psychometrics-candidate-outcomes.html#smote-sampling",
    "title": "psychometrics-candidate-outcomes",
    "section": "",
    "text": "Synthetic Minority Over-sampling Technique (SMOTE) was used to address class imbalances before additional analyses were performed. SMOTE identifies a minority sample, finds its ùëò-nearest neighbors, and generates new synthetic data points so that classes are equally represented.\n\n\nShow code\n# Each of the outcome variables is treated separately as the target for SMOTE.\n# After applying SMOTE for one target, you get a new balanced data set only for that target. Thus, you end up with five separate balanced data sets (one for each outcome variable).\n\n# Drop empty levels after filtering. \nsmote_data &lt;- raw_data %&gt;%\n  mutate(Current_Employment_Status = droplevels(Current_Employment_Status))\n\n\n\n\nShow code\n#  Apply SMOTE for each target variable separately\n# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n# 1. Placement_Contract_Completion \n\nset.seed(2025)\n\nbalanced_contract &lt;- smotenc(\n  df     = smote_data,                        # full data frame\n  var    = \"Placement_Contract_Completion\",   # target column name (must be factor)\n  k      = 5,                                            # nearest neighbors\n  over_ratio = 1                                         # 1 = balance to 1:1; &gt;1 oversamples minority more\n)\n\n# Check result\ntable(balanced_contract$Placement_Contract_Completion) / nrow(balanced_contract)\n\n\n\nIn progress          No         Yes \n  0.3333333   0.3333333   0.3333333 \n\n\nShow code\nkable(balanced_contract %&gt;%\n  dplyr::select(c(Placement_Contract_Completion)) %&gt;% \n  group_by(Placement_Contract_Completion) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nPlacement_Contract_Completion\ncount\n\n\n\n\nIn progress\n142\n\n\nNo\n142\n\n\nYes\n142\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_training &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Specialised_Training_Completion\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_training$Specialised_Training_Completion) / nrow(balanced_training)\n\n\n\n No Yes \n0.5 0.5 \n\n\nShow code\nkable(balanced_training %&gt;%\n  dplyr::select(c(Specialised_Training_Completion)) %&gt;% \n  group_by(Specialised_Training_Completion) %&gt;%\n  dplyr::summarise(count = n()))\n\n\n\n\n\nSpecialised_Training_Completion\ncount\n\n\n\n\nNo\n180\n\n\nYes\n180\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_employment_status &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Current_Employment_Status\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_employment_status$Current_Employment_Status) / nrow(balanced_employment_status)\n\n\n\n         Full_time          Part_time Temporary_Contract         Unemployed \n              0.25               0.25               0.25               0.25 \n\n\nShow code\nkable(balanced_employment_status %&gt;%\n  dplyr::select(c(Current_Employment_Status)) %&gt;% \n  group_by(Current_Employment_Status) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nCurrent_Employment_Status\ncount\n\n\n\n\nFull_time\n118\n\n\nPart_time\n118\n\n\nTemporary_Contract\n118\n\n\nUnemployed\n118\n\n\n\n\n\n\n\nShow code\nset.seed(2025)\n\nbalanced_studies &lt;- smotenc(\n  df     = smote_data,                           \n  var    = \"Further_Studies\",    \n  k      = 5,                                           \n  over_ratio = 1                                         \n)\n\n# Check result\ntable(balanced_studies$Further_Studies) / nrow(balanced_studies)\n\n\n\n No Yes \n0.5 0.5 \n\n\nShow code\nkable(balanced_studies %&gt;%\n  dplyr::select(c(Further_Studies)) %&gt;% \n  group_by(Further_Studies) %&gt;%\n  dplyr::summarise(count = n())) \n\n\n\n\n\nFurther_Studies\ncount\n\n\n\n\nNo\n197\n\n\nYes\n197"
  },
  {
    "objectID": "psychometrics-candidate-outcomes.html#analysis-of-predictive-performance-using-roc-curves",
    "href": "psychometrics-candidate-outcomes.html#analysis-of-predictive-performance-using-roc-curves",
    "title": "psychometrics-candidate-outcomes",
    "section": "",
    "text": "Logistic regression models were used to examine the extent to which three DRA variables (i.e., predictors) could discriminate between two binary outcomes.\nTwo outcomes selected for this analysis:\n\nSpecialised Training Completion (Yes / No)\n\nFurther Studies (Yes / No)\n\n\n\nThe models use these three variables:\n\nComposite Risk Score\nPrinciples\n\nEmotional Understanding\n\nFor each outcome, the data were split into training (80%) and test (20%) sets using stratified sampling to maintain class proportions. Logistic regression models were fitted on the training data, and performance was evaluated on the held-out test set.\n\n\n\nAUC (Area Under the ROC Curve): Measures overall ability to rank candidates correctly. AUC = 0.5 means no discrimination (random guessing); AUC &gt; 0.7‚Äì0.8 is generally useful in applied settings.\nAccuracy: Overall % correct predictions (TP + TN) / total\nPrecision (for Yes): Of all candidates predicted to complete training / pursue further studies, what % were actually Yes? (TP / (TP + FP))\nRecall (for Yes): What proportion of actual Yes cases does the model correctly identify as Yes? Formula: TP / (TP + FN)\n\n\n\nShow code\npredictors &lt;- c(\"Composite_Risk_Score\", \"Principles\", \"Emotional_Understanding\") \n\nevaluate_binary_outcome &lt;- function(outcome) {\n  \n  cat(\"\\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\")\n  cat(\"Binary Outcome:\", outcome$name, \"\\n\")\n  cat(\"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\\n\")\n  \n  df &lt;- outcome$data\n  target_var &lt;- outcome$name\n  pos &lt;- outcome$positive\n  neg &lt;- setdiff(levels(df[[target_var]]), pos)\n  \n  df[[target_var]] &lt;- as.factor(df[[target_var]])\n  \n  # Train/test split\n  set.seed(2025)\n  train_idx &lt;- createDataPartition(df[[target_var]], p = 0.8, list = FALSE)\n  train &lt;- df[train_idx, ]\n  test  &lt;- df[-train_idx, ]\n  \n  # Logistic regression\n  formula &lt;- as.formula(paste(target_var, \"~\", paste(predictors, collapse = \" + \")))\n  model &lt;- glm(formula, data = train, family = \"binomial\")\n  \n  # Predictions\n  pred_prob &lt;- predict(model, newdata = test, type = \"response\")\n  pred_class &lt;- factor(ifelse(pred_prob &gt;= 0.5, pos, neg), levels = c(neg, pos))\n  \n  # ROC\n  roc_obj &lt;- roc(\n    response  = test[[target_var]],\n    predictor = pred_prob,\n    levels    = c(neg, pos),\n    direction = \"&lt;\"\n  )\n  \n  # ggplot ROC\n  library(ggplot2)\n  p &lt;- ggroc(roc_obj, legacy.axes = TRUE) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"grey50\") +\n    labs(\n      title = paste(\"ROC Curve -\", outcome$name),\n      subtitle = paste(\"Positive class:\", pos),\n      x = \"1 - Specificity\",\n      y = \"Sensitivity\"\n    ) +\n    annotate(\"text\", x = 0.75, y = 0.25,\n             label = paste(\"AUC =\", round(auc(roc_obj), 3)),\n             size = 5, color = \"black\") +\n    theme_minimal(base_size = 13) +\n    coord_equal(ratio = 1)\n  \n  print(p)\n  \n  cat(\"AUC:\", round(auc(roc_obj), 3), \"\\n\\n\")\n  \n  # Confusion matrix\n  cm &lt;- conf_mat(\n    tibble(truth = test[[target_var]], estimate = pred_class),\n    truth = truth, estimate = estimate\n  )\n  \n# Extract the table \ntab &lt;- cm$table\n\n# Compute key metrics \ntn &lt;- tab[\"No\", \"No\"]\nfp &lt;- tab[\"Yes\", \"No\"]\nfn &lt;- tab[\"No\", \"Yes\"]\ntp &lt;- tab[\"Yes\", \"Yes\"]\n\ntotal &lt;- sum(tab)\naccuracy &lt;- (tp + tn) / total\nprecision &lt;- tp / (tp + fp)     # PPV for \"Yes\"\nrecall &lt;- tp / (tp + fn)        # sensitivity for \"Yes\"\nf1 &lt;- 2 * (precision * recall) / (precision + recall)\n\ncat(\"\\nConfusion Matrix:\\n\")\nprint(tab)\n\ncat(\"\\nAccuracy:   \", round(accuracy, 3), \"\\n\")\ncat(\"Precision:  \", round(precision, 3), \" (for Yes)\\n\")\ncat(\"Recall:     \", round(recall, 3), \" (for Yes)\\n\")\ncat(\"F1-score:   \", round(f1, 3), \"\\n\\n\")\n\n  invisible(list(model = model, roc = roc_obj, cm = cm, metrics = metrics))\n}\n\n\n\n\nShow code\n# Binary ones\nbinary_outcomes &lt;- list(\n  list(name = \"Specialised_Training_Completion\", \n       data = balanced_training, \n       positive = \"Yes\"),\n  list(name = \"Further_Studies\",                 \n       data = balanced_studies,   \n       positive = \"Yes\")\n)\n\n\nresults_binary &lt;- lapply(binary_outcomes, evaluate_binary_outcome)\n\n\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nBinary Outcome: Specialised_Training_Completion \n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n\n\n\n\nAUC: 0.529 \n\n\nConfusion Matrix:\n          Truth\nPrediction No Yes\n       No  15  14\n       Yes 21  22\n\nAccuracy:    0.514 \nPrecision:   0.512  (for Yes)\nRecall:      0.611  (for Yes)\nF1-score:    0.557 \n\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nBinary Outcome: Further_Studies \n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n\n\n\n\nAUC: 0.512 \n\n\nConfusion Matrix:\n          Truth\nPrediction No Yes\n       No  16  15\n       Yes 23  24\n\nAccuracy:    0.513 \nPrecision:   0.511  (for Yes)\nRecall:      0.615  (for Yes)\nF1-score:    0.558 \n\n\n\n\n\n\nAUC: 0.529 (near-random discrimination)\n\n\n\nAccuracy: 0.514 (correct classifications ~51%)\nPrecision (Yes): 0.512 ‚Äî Of predicted Yes, 51.2% were actual Yes\nRecall (Yes): 0.611 ‚Äî Caught 61.1% of actual Yes cases\nF1-score (Yes): 0.557 ‚Äî Balanced precision/recall\n\n\n\n\nThis shows how the model classified the test set (using 0.5 probability threshold). - True Negatives (TN): 15 candidates correctly predicted as No - False Negatives (FN): 14 candidates wrongly predicted as No (actually Yes) - False Positives (FP): 21 candidates wrongly predicted as Yes (actually No) - True Positives (TP): 22 candidates correctly predicted as Yes\nInsight: The model struggles to distinguish training completion. This outcome may depend more on programme factors than initial risk scores.\n\n\n\n\nAUC: 0.512 (near-random discrimination)\n\n\n\nAccuracy: 0.513 (correct classifications ~51%)\nPrecision (Yes): 0.511 ‚Äî Of predicted Yes, 51.1% were actual Yes\nRecall (Yes): 0.615 ‚Äî Caught 61.5% of actual Yes cases\nF1-score (Yes): 0.558 ‚Äî Balanced precision/recall\n\n\n\n\nThis shows how the model classified the test set (using 0.5 probability threshold). - True Negatives (TN): 16 candidates correctly predicted as No - False Negatives (FN): 15 candidates wrongly predicted as No (actually Yes) - False Positives (FP): 23 candidates wrongly predicted as Yes (actually No) - True Positives (TP): 24 candidates correctly predicted as Yes\nInsight: Similar to training completion, the three predictors explain almost nothing about whether employees pursue further studies.\nOverall ROC Insight: For these specific outcomes, the predictors (i.e., Principles, Emotional Understanding, and Composite Risk) showed limited discriminate ability and modest classification performance on the balanced test sets. Combining with other data (e.g., engagement metrics) could improve validity."
  },
  {
    "objectID": "psychometrics-candidate-outcomes.html#predictive-modeling---random-forest",
    "href": "psychometrics-candidate-outcomes.html#predictive-modeling---random-forest",
    "title": "psychometrics-candidate-outcomes",
    "section": "",
    "text": "First, a random forest model (2000 trees) was trained to predict Employment Status using the following predictors: Core Traits, Emotional Understanding, Judgement, Principles, Uncertainty, and Composite Risk Score.\n\n\nShow code\nbalanced_employment_status_RF_df &lt;- balanced_employment_status   \n\npredictors &lt;- c(\"Core_Traits\", \"Emotional_Understanding\", \"Judgement\", \"Principles\", \"Uncertainty\", \"Composite_Risk_Score\")  \n\n# Quick check\ncat(\"Number of predictors:\", length(predictors), \"\\n\")\n\n\nNumber of predictors: 6 \n\n\nShow code\ncat(\"Outcome levels:\", levels(balanced_employment_status_RF_df$Current_Employment_Status), \"\\n\\n\")\n\n\nOutcome levels: Full_time Part_time Temporary_Contract Unemployed \n\n\nShow code\nstr(balanced_employment_status_RF_df[, c(\"Current_Employment_Status\", head(predictors, 5))])\n\n\ntibble [472 √ó 6] (S3: tbl_df/tbl/data.frame)\n $ Current_Employment_Status: Factor w/ 4 levels \"Full_time\",\"Part_time\",..: 4 3 1 3 3 3 3 1 3 3 ...\n $ Core_Traits              : num [1:472] 4.22 25.8 3.31 7.7 12.93 ...\n $ Emotional_Understanding  : num [1:472] 6.92 23 94.2 25.17 17.73 ...\n $ Judgement                : num [1:472] 32.6 61.7 28.3 47.6 51.6 ...\n $ Principles               : num [1:472] 3.83 57.1 78.62 34.03 64.52 ...\n $ Uncertainty              : num [1:472] 0 52.9 52.9 0 0 ...\n\n\nShow code\n############################################################\n# Train / test split (70 / 30) \n############################################################\nset.seed(2025)\n\ntrain_index &lt;- createDataPartition(\n  balanced_employment_status_RF_df$Current_Employment_Status, \n  p = 0.7, \n  list = FALSE\n)\n\ntrain_data &lt;- balanced_employment_status_RF_df[train_index, ]\ntest_data  &lt;- balanced_employment_status_RF_df[-train_index, ]\n\ncat(\"Training set rows:\", nrow(train_data), \"\\n\")\n\n\nTraining set rows: 332 \n\n\nShow code\ncat(\"Test set rows:    \", nrow(test_data), \"\\n\\n\")\n\n\nTest set rows:     140 \n\n\nShow code\n############################################################\n# Fit Random Forest model (multi-class)\n############################################################\nrf_model &lt;- randomForest(\n  x = train_data[, predictors],          \n  y = train_data$Current_Employment_Status,\n  ntree = 2000,                             # number of trees\n  mtry = floor(sqrt(length(predictors))),   # default for classification\n  importance = TRUE,                        # for variable importance\n  proximity = FALSE,                     \n  na.action = na.roughfix                \n)\n\n# Print model summary\nprint(rf_model)\n\n\n\nCall:\n randomForest(x = train_data[, predictors], y = train_data$Current_Employment_Status,      ntree = 2000, mtry = floor(sqrt(length(predictors))), importance = TRUE,      proximity = FALSE, na.action = na.roughfix) \n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 36.14%\nConfusion matrix:\n                   Full_time Part_time Temporary_Contract Unemployed\nFull_time                 66         8                  6          3\nPart_time                  2        72                  4          5\nTemporary_Contract        15        11                 32         25\nUnemployed                12        12                 17         42\n                   class.error\nFull_time            0.2048193\nPart_time            0.1325301\nTemporary_Contract   0.6144578\nUnemployed           0.4939759\n\n\nShow code\n############################################################\n# Predictions on test data\n############################################################\nrf_pred_class &lt;- predict(rf_model, newdata = test_data[, predictors])\n\nrf_pred_prob &lt;- predict(\n  rf_model,\n  newdata = test_data[, predictors],\n  type = \"prob\"\n)\n\n############################################################\n# Confusion matrix & performance metrics\n############################################################\ncm_caret &lt;- confusionMatrix(\n  data      = rf_pred_class,\n  reference = test_data$Current_Employment_Status\n)\n\nprint(cm_caret)\n\n\nConfusion Matrix and Statistics\n\n                    Reference\nPrediction           Full_time Part_time Temporary_Contract Unemployed\n  Full_time                 24         4                  6          6\n  Part_time                  4        30                  7          1\n  Temporary_Contract         3         0                 14          6\n  Unemployed                 4         1                  8         22\n\nOverall Statistics\n                                         \n               Accuracy : 0.6429         \n                 95% CI : (0.5575, 0.722)\n    No Information Rate : 0.25           \n    P-Value [Acc &gt; NIR] : &lt;2e-16         \n                                         \n                  Kappa : 0.5238         \n                                         \n Mcnemar's Test P-Value : 0.192          \n\nStatistics by Class:\n\n                     Class: Full_time Class: Part_time\nSensitivity                    0.6857           0.8571\nSpecificity                    0.8476           0.8857\nPos Pred Value                 0.6000           0.7143\nNeg Pred Value                 0.8900           0.9490\nPrevalence                     0.2500           0.2500\nDetection Rate                 0.1714           0.2143\nDetection Prevalence           0.2857           0.3000\nBalanced Accuracy              0.7667           0.8714\n                     Class: Temporary_Contract Class: Unemployed\nSensitivity                             0.4000            0.6286\nSpecificity                             0.9143            0.8762\nPos Pred Value                          0.6087            0.6286\nNeg Pred Value                          0.8205            0.8762\nPrevalence                              0.2500            0.2500\nDetection Rate                          0.1000            0.1571\nDetection Prevalence                    0.1643            0.2500\nBalanced Accuracy                       0.6571            0.7524\n\n\nShow code\n# Overall accuracy\ncat(\"\\nOverall Accuracy:\", round(cm_caret$overall[\"Accuracy\"], 3), \"\\n\")\n\n\n\nOverall Accuracy: 0.643 \n\n\nShow code\n# Per-class precision, recall, F1 \ncat(\"\\nPer-class metrics:\\n\")\n\n\n\nPer-class metrics:\n\n\nShow code\nprint(cm_caret$byClass[, c(\"Precision\", \"Recall\", \"F1\")])\n\n\n                          Precision    Recall        F1\nClass: Full_time          0.6000000 0.6857143 0.6400000\nClass: Part_time          0.7142857 0.8571429 0.7792208\nClass: Temporary_Contract 0.6086957 0.4000000 0.4827586\nClass: Unemployed         0.6285714 0.6285714 0.6285714\n\n\nShow code\n# Macro-averaged metrics (simple average across classes)\nmacro_precision &lt;- mean(cm_caret$byClass[, \"Precision\"], na.rm = TRUE)\nmacro_recall    &lt;- mean(cm_caret$byClass[, \"Recall\"], na.rm = TRUE)\nmacro_f1        &lt;- mean(cm_caret$byClass[, \"F1\"], na.rm = TRUE)\n\ncat(\"\\nMacro-averaged:\\n\")\n\n\n\nMacro-averaged:\n\n\nShow code\ncat(\"Precision:\", round(macro_precision, 3), \"\\n\")\n\n\nPrecision: 0.638 \n\n\nShow code\ncat(\"Recall:   \", round(macro_recall,    3), \"\\n\")\n\n\nRecall:    0.643 \n\n\nShow code\ncat(\"F1:       \", round(macro_f1,        3), \"\\n\")\n\n\nF1:        0.633 \n\n\nShow code\n############################################################\n# Multi-class AUC (macro-averaged)\n############################################################\nmulti_auc &lt;- multiclass.roc(\n  response  = test_data$Current_Employment_Status,\n  predictor = rf_pred_prob\n)\n\ncat(\"\\nMulti-class AUC (macro-averaged):\", round(auc(multi_auc), 3), \"\\n\")\n\n\n\nMulti-class AUC (macro-averaged): 0.875 \n\n\nShow code\n############################################################\n# Variable importance\n############################################################\ncat(\"\\nVariable Importance (MeanDecreaseGini):\\n\")\n\n\n\nVariable Importance (MeanDecreaseGini):\n\n\nShow code\nimportance(rf_model) %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"Predictor\") %&gt;%\n  arrange(desc(MeanDecreaseGini)) %&gt;%\n  head(15) %&gt;%               # top 15\n  print()\n\n\n                Predictor Full_time Part_time Temporary_Contract Unemployed\n1 Emotional_Understanding  89.30430  98.76786         11.9130505   23.82122\n2              Principles  71.66467  73.81713          5.6151620   34.65674\n3    Composite_Risk_Score  66.43196  62.26855         -0.8070441   47.36499\n4             Core_Traits  62.68984  53.81674         -5.4520896   33.14145\n5               Judgement  50.70257  62.13475         -1.9497412   16.89340\n6             Uncertainty  39.98729  56.67910          1.4615802   23.09460\n  MeanDecreaseAccuracy MeanDecreaseGini\n1            111.17026         51.07874\n2             90.07002         47.53747\n3             88.58889         46.47894\n4             71.82570         40.47700\n5             70.54355         39.95138\n6             60.60349         22.74974\n\n\nShow code\n# Plot\nvarImpPlot(rf_model, main = \"Random Forest Variable Importance - Current Employment Status\")\n\n\n\n\n\nCore Traits and Emotional Understanding are the strongest predictors of Employment Status. Uncertainty is the weakest predictor.\nA second random forest model (2000 trees) was trained to predict Work Placement Contract Completion using the following predictors: Core Traits, Emotional Understanding, Judgement, Principles, Uncertainty, and Composite Risk Score.\n\n\nShow code\n# Random Forests for Work_Placement_Contract \n\nbalanced_contract_RF_df &lt;- balanced_contract  \n\npredictors &lt;- c(\"Core_Traits\", \"Emotional_Understanding\", \"Judgement\", \"Principles\", \"Uncertainty\", \"Composite_Risk_Score\")  \n\n# Quick check\ncat(\"Number of predictors:\", length(predictors), \"\\n\")\n\n\nNumber of predictors: 6 \n\n\nShow code\ncat(\"Outcome levels:\", levels(balanced_contract_RF_df$Placement_Contract_Completion), \"\\n\\n\")\n\n\nOutcome levels: In progress No Yes \n\n\nShow code\nstr(balanced_contract_RF_df[, c(\"Placement_Contract_Completion\", head(predictors, 5))])\n\n\ntibble [426 √ó 6] (S3: tbl_df/tbl/data.frame)\n $ Placement_Contract_Completion: Factor w/ 3 levels \"In progress\",..: 1 3 3 1 2 1 3 3 3 3 ...\n $ Core_Traits                  : num [1:426] 4.22 25.8 3.31 7.7 12.93 ...\n $ Emotional_Understanding      : num [1:426] 6.92 23 94.2 25.17 17.73 ...\n $ Judgement                    : num [1:426] 32.6 61.7 28.3 47.6 51.6 ...\n $ Principles                   : num [1:426] 3.83 57.1 78.62 34.03 64.52 ...\n $ Uncertainty                  : num [1:426] 0 52.9 52.9 0 0 ...\n\n\nShow code\n############################################################\n# Train / test split (70 / 30) \n############################################################\nset.seed(2025)\n\ntrain_index &lt;- createDataPartition(\n  balanced_contract_RF_df$Placement_Contract_Completion, \n  p = 0.7, \n  list = FALSE\n)\n\ntrain_data &lt;- balanced_contract_RF_df[train_index, ]\ntest_data  &lt;- balanced_contract_RF_df[-train_index, ]\n\ncat(\"Training set rows:\", nrow(train_data), \"\\n\")\n\n\nTraining set rows: 300 \n\n\nShow code\ncat(\"Test set rows:    \", nrow(test_data), \"\\n\\n\")\n\n\nTest set rows:     126 \n\n\nShow code\n############################################################\n# Fit Random Forest model (multi-class)\n############################################################\nrf_model &lt;- randomForest(\n  x = train_data[, predictors],          \n  y = train_data$Placement_Contract_Completion,\n  ntree = 2000,                             # number of trees\n  mtry = floor(sqrt(length(predictors))),   # default for classification\n  importance = TRUE,                        # for variable importance\n  proximity = FALSE,                     \n  na.action = na.roughfix                \n)\n\n# Print model summary\nprint(rf_model)\n\n\n\nCall:\n randomForest(x = train_data[, predictors], y = train_data$Placement_Contract_Completion,      ntree = 2000, mtry = floor(sqrt(length(predictors))), importance = TRUE,      proximity = FALSE, na.action = na.roughfix) \n               Type of random forest: classification\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 27.33%\nConfusion matrix:\n            In progress No Yes class.error\nIn progress          69 11  20        0.31\nNo                    6 84  10        0.16\nYes                  23 12  65        0.35\n\n\nShow code\n############################################################\n# Predictions on test data\n############################################################\nrf_pred_class &lt;- predict(rf_model, newdata = test_data[, predictors])\n\nrf_pred_prob &lt;- predict(\n  rf_model,\n  newdata = test_data[, predictors],\n  type = \"prob\"\n)\n\n############################################################\n# Confusion matrix & performance metrics\n############################################################\ncm_caret &lt;- confusionMatrix(\n  data      = rf_pred_class,\n  reference = test_data$Placement_Contract_Completion\n)\n\nprint(cm_caret)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    In progress No Yes\n  In progress          29  3  14\n  No                    3 33   5\n  Yes                  10  6  23\n\nOverall Statistics\n                                          \n               Accuracy : 0.6746          \n                 95% CI : (0.5854, 0.7554)\n    No Information Rate : 0.3333          \n    P-Value [Acc &gt; NIR] : 5.529e-15       \n                                          \n                  Kappa : 0.5119          \n                                          \n Mcnemar's Test P-Value : 0.8596          \n\nStatistics by Class:\n\n                     Class: In progress Class: No Class: Yes\nSensitivity                      0.6905    0.7857     0.5476\nSpecificity                      0.7976    0.9048     0.8095\nPos Pred Value                   0.6304    0.8049     0.5897\nNeg Pred Value                   0.8375    0.8941     0.7816\nPrevalence                       0.3333    0.3333     0.3333\nDetection Rate                   0.2302    0.2619     0.1825\nDetection Prevalence             0.3651    0.3254     0.3095\nBalanced Accuracy                0.7440    0.8452     0.6786\n\n\nShow code\n# Overall accuracy\ncat(\"\\nOverall Accuracy:\", round(cm_caret$overall[\"Accuracy\"], 3), \"\\n\")\n\n\n\nOverall Accuracy: 0.675 \n\n\nShow code\n# Per-class precision, recall, F1 \ncat(\"\\nPer-class metrics:\\n\")\n\n\n\nPer-class metrics:\n\n\nShow code\nprint(cm_caret$byClass[, c(\"Precision\", \"Recall\", \"F1\")])\n\n\n                   Precision    Recall        F1\nClass: In progress 0.6304348 0.6904762 0.6590909\nClass: No          0.8048780 0.7857143 0.7951807\nClass: Yes         0.5897436 0.5476190 0.5679012\n\n\nShow code\n# Macro-averaged metrics (simple average across classes)\nmacro_precision &lt;- mean(cm_caret$byClass[, \"Precision\"], na.rm = TRUE)\nmacro_recall    &lt;- mean(cm_caret$byClass[, \"Recall\"], na.rm = TRUE)\nmacro_f1        &lt;- mean(cm_caret$byClass[, \"F1\"], na.rm = TRUE)\n\ncat(\"\\nMacro-averaged:\\n\")\n\n\n\nMacro-averaged:\n\n\nShow code\ncat(\"Precision:\", round(macro_precision, 3), \"\\n\")\n\n\nPrecision: 0.675 \n\n\nShow code\ncat(\"Recall:   \", round(macro_recall,    3), \"\\n\")\n\n\nRecall:    0.675 \n\n\nShow code\ncat(\"F1:       \", round(macro_f1,        3), \"\\n\")\n\n\nF1:        0.674 \n\n\nShow code\n############################################################\n# Multi-class AUC (macro-averaged)\n############################################################\nmulti_auc &lt;- multiclass.roc(\n  response  = test_data$Placement_Contract_Completion,\n  predictor = rf_pred_prob\n)\n\ncat(\"\\nMulti-class AUC (macro-averaged):\", round(auc(multi_auc), 3), \"\\n\")\n\n\n\nMulti-class AUC (macro-averaged): 0.847 \n\n\nShow code\n############################################################\n# Variable importance\n############################################################\ncat(\"\\nVariable Importance (MeanDecreaseGini):\\n\")\n\n\n\nVariable Importance (MeanDecreaseGini):\n\n\nShow code\nimportance(rf_model) %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"Predictor\") %&gt;%\n  arrange(desc(MeanDecreaseGini)) %&gt;%\n  head(15) %&gt;%               # top 15\n  print()\n\n\n                Predictor In progress       No       Yes MeanDecreaseAccuracy\n1             Core_Traits    44.61575 88.98770 16.066408             86.06533\n2 Emotional_Understanding    54.07565 73.78543 34.761558             87.00799\n3              Principles    47.78354 81.97185  9.275946             80.24299\n4               Judgement    33.48851 45.19150 13.086894             53.07396\n5    Composite_Risk_Score    30.32766 56.88619  3.774848             57.22316\n6             Uncertainty    22.22296 51.93331 16.833642             52.50164\n  MeanDecreaseGini\n1         41.04164\n2         40.51270\n3         37.21400\n4         31.54092\n5         29.72965\n6         19.30408\n\n\nShow code\n# Plot\nvarImpPlot(rf_model, main = \"Random Forest Variable Importance - Placement Contract Completion\")\n\n\n\n\n\nCore Traits and Emotional Understanding are the strongest drivers of whether someone completes their placement contract, is still in progress, or does not complete it. Uncertainty contributes the least."
  }
]